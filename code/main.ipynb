{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8c378f",
   "metadata": {},
   "source": [
    "# Homodyne tomography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from qutip import Qobj, wigner\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "from scipy.fft import rfft, irfft, rfftfreq\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Importing functions\n",
    "from utils import *\n",
    "\n",
    "from iMLE import *\n",
    "\n",
    "from BME import *\n",
    "\n",
    "# Global plot style settings\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"DejaVu Serif\"],\n",
    "    \"mathtext.fontset\": \"cm\",            # Use Computer Modern for math\n",
    "    \"font.size\": 14,                     # Base font size\n",
    "    \"axes.labelsize\": 16,                # Axis label font size\n",
    "    \"axes.titlesize\": 16,                # Title font size\n",
    "    \"legend.fontsize\": 13,               # Legend font size\n",
    "    \"xtick.labelsize\": 13,               # X tick label size\n",
    "    \"ytick.labelsize\": 13,               # Y tick label size\n",
    "    \"axes.linewidth\": 1.2,               # Thicker axis lines\n",
    "    \"xtick.direction\": \"in\",             # x-yick direction\n",
    "    \"ytick.direction\": \"in\",             # y-tick direction\n",
    "    \"text.usetex\": False,                # Enable LaTeX if needed\n",
    "    \"figure.dpi\": 100,                   # Good resolution for screens\n",
    "    \"savefig.dpi\": 300                   # High resolution for saving\n",
    "})\n",
    "\n",
    "# Define function for nice plotting\n",
    "def PlotSettings(ax, gridlines=False, minimalist=False):\n",
    "    # Minor ticks\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    # Minimalist style\n",
    "    if minimalist:\n",
    "        # Hide top and right spines (borders)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # Ticks only on bottom and left\n",
    "        ax.tick_params(which='both', top=False, right=False)\n",
    "    else:\n",
    "        # Tick parameters\n",
    "        ax.tick_params(which='both', direction='in', top=True, right=True)\n",
    "        ax.tick_params(which='major', length=7, width=1.2)\n",
    "        ax.tick_params(which='minor', length=4, width=1)\n",
    "    # Optional grid\n",
    "    if gridlines:\n",
    "        ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=0.6, alpha=0.7)\n",
    "        ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222219d",
   "metadata": {},
   "source": [
    "### What is Homodyne tomography?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad76e6f",
   "metadata": {},
   "source": [
    "Homodyne tomography is a method for reconstructing quantum states of light by measuring field quadratures $Q_\\theta$ at different local oscillator (LO) phases $\\theta$ using a Homodyne detection scheme. From these measurements, one can recover the Wigner function $W(Q,P)$ and density matrix $\\rho$, which makes it a key tool for verifying the preparation of nonclassical states in quantum optics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbd0fa",
   "metadata": {},
   "source": [
    "<img src=\"../images/HomodyneTomography.png\" alt=\"Homodyne Tomography\" height=\"250\"/>\n",
    "<img src=\"../images/HomodyneDetector.png\" alt=\"Homodyne Detector\" height=\"250\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c270ba",
   "metadata": {},
   "source": [
    "In the paper *Optical Continuous-Variable Qubit* (see references), superpositions of squeezed vacuum and squeezed single-photon states were engineered using photon subtraction. The setup employed an optical parametric oscillator (OPO) to generate squeezed vacuum, a small fraction of which was tapped off, displaced, and detected by an avalanche photodiode (APD). Conditional detection prepared the desired superpositions, which were then analyzed using balanced homodyne detection across multiple LO phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d651e",
   "metadata": {},
   "source": [
    "<img src=\"../images/ExperimentalSetup.png\" alt=\"Homodyne Tomography\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89441e2f",
   "metadata": {},
   "source": [
    "In this notebook, we work with the experimental data obtained using this setup. Our goal is to benchmark and compare two different reconstruction methods - Maximum Likelihood Estimation (MLE) and Bayesian Mean Estimation (BME) - to reproduce the Wigner functions reported in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e699732",
   "metadata": {},
   "source": [
    "### Loading and processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f52fe",
   "metadata": {},
   "source": [
    "We start by downloading and un-zipping the data from the dropbox link bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de733e",
   "metadata": {},
   "source": [
    "https://www.dropbox.com/scl/fi/0cb9i9vx9w0b1lpro8wpq/data-tora.zip?rlkey=nkouczz7r9ylnmkd3n639z7kt&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188665a3",
   "metadata": {},
   "source": [
    "After downloading and un-zipping, put the **data-tora** folder into the **data** folder in the repo. The folder contains 3 different dates **091027**, **091028** and **091029** each containing a collection of measurements of different states - like **cat1** or **tora5**.\n",
    "For each state 30,000 measurements were performed at the angles 0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, as well as a vacuum measurement for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5ab42",
   "metadata": {},
   "source": [
    "The data was acquired by a LeCroy HDO6034 oscilloscope. Since it is in a proprietary binary format, we use the script **lecroy.py** to import it. Based on the folder and file structure of the **data-tora** folder, we created a script for processing the data collecting all the traces corresponding to different phases into a single .npy file for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c000069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try if it runs, otherwise manually run the preprocessing script\n",
    "#parent = str(Path.cwd().parent)\n",
    "#%run preprocess_data.py {parent}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc75ee2",
   "metadata": {},
   "source": [
    "**Update: Do Not Download File from dropbox. We have included the .npy and .csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e95c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = Path(os.path.dirname(os.getcwd()))\n",
    "date = \"091027\"\n",
    "state = \"cat2\"\n",
    "\n",
    "data_path = parent / \"data\" / \"processed_data\" / date\n",
    "data_raw = np.load(data_path / (state + '.npy'))\n",
    "\n",
    "dt = json.load(open(data_path / 'dts.json'))[state]\n",
    "N = data_raw.shape[2]\n",
    "t = np.linspace(0, dt*N, N, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90966147",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3ae0d",
   "metadata": {},
   "source": [
    "The structure of the .npy file is (n_angles, n_traces, n_measurements). Bellow we plot a single trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(t*1e9, data_raw[0, 0, :])\n",
    "ax.set_xlabel(\"Time (ns)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.set_xlim(0, t[-1]*1e9)\n",
    "PlotSettings(ax, gridlines=True, minimalist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da1953",
   "metadata": {},
   "source": [
    "### Calculating quadrature values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a4d4d",
   "metadata": {},
   "source": [
    "The OPO used in the experiment outputs a continuum of temporal modes, however the conditioned quantum state only occupies a single temporal mode, so we need to perform temporal filtering by selecting a mode function $f_s(t)$ to integrate over, giving us a single quadrature value as\n",
    "$$\n",
    "Q_\\theta=\\int_{-\\infty}^\\infty f_s(t)Q_\\theta(t)dt\n",
    "$$\n",
    "The mode function choosen here is $f_s(t)=\\sqrt{\\gamma}e^{-\\gamma|t-t_0|}$, where $\\gamma$ is the total decay rate of the OPO - corresponding to the HWHM (half-widthhalf-maximum) bandwidth of the approximately Lorentzian shaped resonances, and $t_0$ is the exact time a photon is subtracted from the state. The total decay rate is calculated as $\\gamma=2\\pi f$, with $f=9$ MHz being the bandwidth of the OPO. The time $t_0$ can be estimated by calculating the variance over all the traces for a given angle and then finding the maximum of the peak. This can be seen on the plots bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "#fig.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Subplot 1\n",
    "for i in range(12):\n",
    "    state = data_raw[i,:,:]\n",
    "    state_var = state.var(axis=0)\n",
    "    ax1.plot(t*1e9, state_var, label=f'{15*i} deg')\n",
    "# Make legend in 2 columns\n",
    "ax1.legend(ncol=2)\n",
    "# Set title and labels\n",
    "ax1.set_title(\"Variance of different angles\")\n",
    "ax1.set_xlabel(\"Time (ns)\")\n",
    "ax1.set_ylabel(\"Variance\")\n",
    "PlotSettings(ax1, gridlines=True, minimalist=True)\n",
    "\n",
    "# Subplot 2\n",
    "# Extract vacuum data\n",
    "vacuum = data_raw[-1,:,:]\n",
    "# Define temporal mode from peak in variance\n",
    "temporal_mode = fs(t, t[39])  # shape (T,)\n",
    "# Plot\n",
    "ax2.plot(t*1e9, temporal_mode)\n",
    "# Set title and labels\n",
    "ax2.set_title(\"Extracted Temporal Mode\")\n",
    "ax2.set_xlabel(\"Time (ns)\")\n",
    "ax2.set_ylabel(\"Amplitude\")\n",
    "PlotSettings(ax2, gridlines=True, minimalist=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507cb73",
   "metadata": {},
   "source": [
    "By automating this procedure, we can process all the .npy arrays and make dataframes in .csv files which contain only the quadrature values for the 12 different angles. These values are normalized with respect to the vacuum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dec01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "parent = Path(os.path.dirname(os.getcwd()))\n",
    "date = \"091027\"\n",
    "state = \"cat2\"\n",
    "\n",
    "data_path = parent / \"data\" / \"dataframes\" / date\n",
    "data_quadratures = pd.read_csv(data_path / (state + '.csv'))\n",
    "data_quadratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "x_values = np.array(data_quadratures)\n",
    "x_values = np.swapaxes(x_values, 0, 1)\n",
    "# Make array from 0 to 165 in steps of 15\n",
    "thetas = np.arange(0, 166, 15)\n",
    "# Convert to radians\n",
    "thetas = np.radians(thetas)\n",
    "# Put offset on values\n",
    "x0 = -0.08\n",
    "theta0 = np.deg2rad(147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.hist(x_values[i], bins=100, density=False, alpha=0.4, label=f\"{15*i} deg\")\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(\"Calibrated Quadrature Distributions\")\n",
    "plt.xlabel(\"Quadrature Value, $X_\\\\theta$\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b9173",
   "metadata": {},
   "source": [
    "### Reconstruction algoritms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2863f",
   "metadata": {},
   "source": [
    "In the following reconstruction algorithms, the goal is to reconstruct the unknown quantum state $\\hat{\\rho}$ given a set of quadrature measurements $\\{x_i\\}$ and LO phase angles $\\{\\theta_j\\}$. Each measurement outcome corresponds to projecting the state onto a quadrature eigenstate $|\\theta_j,x_i\\rangle$, and the probability of obtaining that outcome is given by\n",
    "\\begin{equation}\n",
    "P(x_i;\\theta_j)=\\langle\\theta_j,x_i|\\hat{\\rho}|\\theta_j,x_i\\rangle \\tag{1}\n",
    "\\end{equation}\n",
    "To estimate the density matrix that best fits the measured data, one needs to maximize the likelihood function\n",
    "\\begin{equation}\n",
    "\\mathcal{L(\\hat{\\rho})}=\\prod_{i,j}P(x_i;\\theta_j)^{c_i}, \\tag{2}\n",
    "\\end{equation}\n",
    "where $c_i$ is the number of times a particular outcome occurs. In practice, one maximizes the log-likelihood\n",
    "\\begin{equation}\n",
    "\\ln{\\mathcal{L(\\hat{\\rho})}}=\\sum_{i,j} c_i\\ln P(x_i;\\theta_j) \\tag{3}\n",
    "\\end{equation}\n",
    "To calculate the probabilities $P(x_i;\\theta_j)$ given by eq. (1), one can express the quadrature eigenstates in the Fock (or photon number) basis as\n",
    "\\begin{equation}\n",
    "|\\theta_j,x_i\\rangle=\\sum_{n=0}^{N-1}\\langle n|\\theta_j,x_i\\rangle|n\\rangle, \\tag{4}\n",
    "\\end{equation}\n",
    "where the overlap between the number and quadrature eigenstates is given by the well known stationary solution of the Schrödinger equation for a particle in a harmonic potential\n",
    "\\begin{equation}\n",
    "\\langle n|\\theta,x\\rangle=e^{-in\\theta}\\left(\\frac{1}{\\pi}\\right)^{1/4}\\frac{H_n(x)}{\\sqrt{2^nn!}}\\exp(-x^2/2) \\tag{5}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82101104",
   "metadata": {},
   "source": [
    "#### Itterative Maxium Likelihood Estimation (iMLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41beae29",
   "metadata": {},
   "source": [
    "In Maximum Likelihood estimation, the goal is to find the density matrix $\\hat{\\rho}$ which maximizes the likelihood $\\mathcal{L}$ given by eq. (2). To do so, one introduces the iteration operator\n",
    "\\begin{equation}\n",
    "\\hat{R}(\\hat{\\rho})=\\sum_{i,j}\\frac{c_i}{P(x_i;\\theta_j)} |\\theta_j,x_i\\rangle\\langle\\theta_j,x_i| \\tag{6}\n",
    "\\end{equation}\n",
    "Looking at eq. (2) one can see that by inserting the quantum state $\\rho_0$ which is most likely to produce the observed data set, we must have $c_i\\propto P(x_i;\\theta_j)$. Furthermore, since $\\sum_{i,j}|\\theta_j,x_i\\rangle\\langle\\theta_j,x_i|\\propto\\hat{1}$, we find $\\hat{R}(\\hat{\\rho_0})\\propto\\hat{1}$ and thus\n",
    "$$\n",
    "\\hat{R}(\\hat{\\rho_0})\\hat{\\rho_0}\\propto\\hat{\\rho_0}\\hat{R}(\\hat{\\rho_0})\\propto\\hat{\\rho_0}\\Rightarrow\\hat{R}(\\hat{\\rho_0})\\hat{\\rho_0}\\hat{R}(\\hat{\\rho_0})\\propto\\hat{\\rho_0}\n",
    "$$\n",
    "The last relation forms the basis for the iterative algorithm. We start by choosing some initial density matrix e.g. $\\hat{\\rho}^{(0)}=\\mathcal{N}[\\hat{1}]$, where $\\mathcal{N}$ is a normalization to a unitary trace and then apply repetitive itterations over $k$\n",
    "$$\n",
    "\\hat{\\rho}^{(k+1)}=\\mathcal{N}[\\hat{R}(\\hat{\\rho}^{(k)})\\hat{\\rho}^{(k)}\\hat{R}(\\hat{\\rho}^{(k)})],\n",
    "$$\n",
    "each time constructing a new itteration operator as given by eq. (6). The total number of itterations is set by monitoring the likelihood, which will monotonically increase, and then determine when the changes are small enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224128f4",
   "metadata": {},
   "source": [
    "The cell bellow runs the algoritm on the data and plots the change in log-likelihood over itterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running iMLE with N=15 and num_bins=400\n",
    "rhos, likelihoods = run_iMLE(thetas-theta0, x_values-x0, N=15,\n",
    "                             num_bins=400, max_iters=100, tol=1e-1)\n",
    "# Determine total number of measurements and calculate delta log-likelihood per sample\n",
    "n_samples = x_values.size\n",
    "per_sample = np.array(likelihoods) / n_samples\n",
    "delta_ll = per_sample - np.max(per_sample)\n",
    "iterations = np.arange(0, len(delta_ll), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd45305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "#fig.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Subplot 1\n",
    "ax1.plot(iterations[:10], delta_ll[:10], marker=\"o\", lw=1.5)\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Δ log-likelihood per sample\")\n",
    "ax1.set_title(\"Convergence of iMLE\")\n",
    "PlotSettings(ax1, gridlines=True, minimalist=True)\n",
    "#ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2\n",
    "ax2.plot(iterations[10:], delta_ll[10:], marker=\"o\", lw=1.5)\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "#ax2.set_ylabel(\"Log-Likelihood\")\n",
    "ax2.set_title(\"Convergence of iMLE\")\n",
    "PlotSettings(ax2, gridlines=True, minimalist=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb159fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid and parameters\n",
    "xvec = np.linspace(-4, 4, 200)\n",
    "X, Y = np.meshgrid(xvec, xvec)\n",
    "vmin, vmax = -1/np.pi, 1/np.pi\n",
    "levels = np.linspace(vmin, vmax, 41)\n",
    "\n",
    "# Precompute Wigner functions with QuTiP\n",
    "Ws = [wigner(Qobj(rho), xvec, xvec) for rho in tqdm(rhos, desc=\"Computing Wigner functions\")]\n",
    "\n",
    "# Precompute the diagonal elements\n",
    "diagonals = [np.diag(rho).real for rho in rhos]\n",
    "\n",
    "N = rhos[-1].shape[0]\n",
    "# Make array from 0 to N in steps of 1\n",
    "n_values = np.arange(0, N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1, 2, figsize=(14, 6),\n",
    "    gridspec_kw={'width_ratios': [1.5, 1]}\n",
    ")\n",
    "fig.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Subplot 1\n",
    "ax1.set_title('Wigner function')\n",
    "# Filled contours with transparency\n",
    "contour_filled = ax1.contourf(X, Y, Ws[-1], levels=levels,\n",
    "                            cmap='seismic', alpha=0.8, vmin=vmin, vmax=vmax)\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(contour_filled, ax=ax1, ticks=[-1/np.pi, 1/np.pi])\n",
    "cbar.ax.set_yticklabels([r\"$-1/\\pi$\", r\"$1/\\pi$\"])  # custom tick labels if needed\n",
    "# Move axes to cross at (0,0)\n",
    "ax1.spines['left'].set_position('zero')\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.spines['right'].set_color('none')\n",
    "ax1.spines['top'].set_color('none')\n",
    "# Set x- and y-ticks skipping 0\n",
    "ax1.set_xticks([-3, -2, -1, 1, 2, 3])\n",
    "ax1.set_yticks([-3, -2, -1, 1, 2, 3])\n",
    "PlotSettings(ax1, minimalist=True)\n",
    "\n",
    "# Subplot 2\n",
    "ax2.set_title('Photon statistics')\n",
    "\n",
    "for i in range(len(n_values)):\n",
    "    ax2.vlines(n_values[i], 0, diagonals[-1][i], colors='blue', linestyles='dashed')\n",
    "\n",
    "ax2.plot(n_values, diagonals[-1], 'o', color='blue')\n",
    "#ax2.hist(diagonals[-1], bins=len(diagonals[-1]), alpha=0.7)\n",
    "ax2.set_xlabel('Fock state |n>')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_xticks(n_values)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86aa535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Figure setup ---\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1, 2, figsize=(14, 6),\n",
    "    gridspec_kw={'width_ratios': [1.5, 1]}\n",
    ")\n",
    "fig.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Initial contour on ax1\n",
    "contour = ax1.contourf(X, Y, Ws[0], levels=levels,\n",
    "                       cmap=\"seismic\", vmin=vmin, vmax=vmax, alpha=0.8)\n",
    "cbar = fig.colorbar(contour, ax=ax1, ticks=[-1/np.pi, 1/np.pi])\n",
    "cbar.ax.set_yticklabels([r\"$-1/\\pi$\", r\"$1/\\pi$\"])\n",
    "\n",
    "# Ax1 styling\n",
    "ax1.spines['left'].set_position('zero')\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.spines['right'].set_color('none')\n",
    "ax1.spines['top'].set_color('none')\n",
    "ax1.set_xticks([-3, -2, -1, 1, 2, 3])\n",
    "ax1.set_yticks([-3, -2, -1, 1, 2, 3])\n",
    "\n",
    "# Ax2 styling\n",
    "ax2.set_xlabel('Fock state |n>')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_xticks(n_values)\n",
    "PlotSettings(ax2, minimalist=True)\n",
    "\n",
    "# --- Animation functions ---\n",
    "def init():\n",
    "    return []\n",
    "\n",
    "def animate(i):\n",
    "    # --- ax1: update Wigner contour ---\n",
    "    while ax1.collections:\n",
    "        ax1.collections[0].remove()\n",
    "    ax1.set_title(f\"Wigner Function (Iteration {i})\")\n",
    "    contour = ax1.contourf(X, Y, Ws[i], levels=levels,\n",
    "                           cmap=\"seismic\", vmin=vmin, vmax=vmax, alpha=0.8)\n",
    "\n",
    "    # --- ax2: clear and redraw ---\n",
    "    ax2.clear()\n",
    "    ax2.set_xlabel('Fock state |n>')\n",
    "    ax2.set_ylabel('Probability')\n",
    "    ax2.set_xticks(n_values)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    for j, n in enumerate(n_values):\n",
    "        ax2.vlines(n, 0, diagonals[i][j], colors='blue', linestyles='dashed')\n",
    "    ax2.plot(n_values, diagonals[i], 'o', color='blue')\n",
    "\n",
    "    return [contour]  # returning ax2 artists is optional when blit=False\n",
    "\n",
    "# --- Create animation ---\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                              frames=len(rhos), interval=100, blit=False)\n",
    "\n",
    "# --- Display in notebook ---\n",
    "html_anim = HTML(ani.to_jshtml())\n",
    "plt.close(fig)\n",
    "display(html_anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e56d5",
   "metadata": {},
   "source": [
    "#### Bayesian Mean Estimation (BME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dba6e4",
   "metadata": {},
   "source": [
    "BME is a Bayesian approach to estimating parameters of a probability distribution. Here’s the idea step by step, as explained in [X] [this paper](https://iopscience.iop.org/article/10.1088/1367-2630/12/4/043034/pdf):\n",
    "\n",
    "1. Use the data to generate a likelihood function, $\\mathcal{L}(\\rho) = p(M|\\rho)$. $\\mathcal{L}$ is not a probability\n",
    "distribution; it quantifies the relative plausibility of different state assignments.\n",
    "\n",
    "2. Choose a prior distribution over states, $\\pi_{0}(\\rho)d\\rho$. It represents the estimator’s ignorance,\n",
    "and should generally be chosen to be as ‘uniform’, or uninformative, as possible.\n",
    "\n",
    "3. Multiply the prior by the likelihood and normalize to obtain a posterior distribution\n",
    "\n",
    "$$\n",
    "\\pi_{f}(\\rho)d\\rho \\propto \\mathcal{L}(\\rho)\\pi_{0}(\\rho)d\\rho\n",
    "$$ \n",
    "\n",
    "which represents the estimator’s knowledge. The proportionality constant is set by normalization.\n",
    "\n",
    "4. Report the mean of this posterior,\n",
    "\n",
    "$$\n",
    "\\hat\\rho_{BME} = \\int \\rho \\pi_{f}(\\rho)d\\rho\n",
    "$$\n",
    "\n",
    "This is the best concise description of the estimator’s knowledge.\n",
    "\n",
    "The main goal is to find a Markoc chain of density matrices that, when averaged, gives the posterior mean $\\hat\\rho_{BME}$. There are multiple algorithms to build this chain, but in this project we have implemented the Metropolis-hastings method. This works as follows:\n",
    "1. Start with an initial guess for the density matrix $\\rho^{(0)}$. In our case, we have assumed $\\rho^{(0)} = \\frac{I}{N}$, the maximally mixed state.\n",
    "2. Propose a new density matrix $\\rho'$ by perturbing the current state $\\rho$ with a small random step. This is done by Cholesky parametrization, where we decompose the density matrix into a lower triangular matrix T such that \n",
    "$$\n",
    "\\rho = \\frac{T^\\dagger T}{\\mathrm{Tr}(T^\\dagger T)}\n",
    "$$\n",
    "Then, we perturb T by adding a small (multiplied by a factor $\\epsilon$) random (sampled from a $\\mathcal{N}(0,1)$) matrix $\\Delta T$, and the resulting new density matrix is given by:\n",
    "$$\n",
    "\\rho' = \\frac{(T + \\epsilon \\Delta T)^\\dagger (T + \\epsilon \\Delta T)}{\\mathrm{Tr}((T + \\epsilon \\Delta T)^\\dagger (T + \\epsilon \\Delta T))}\n",
    "$$\n",
    "\n",
    "3. Calculate the acceptance probability $\\alpha = \\min\\left(1, \\frac{P(\\rho')}{P(\\rho)}\\right)$. In our case, we use log $\\alpha$ instead, which is given by:\n",
    "$$\n",
    "\\log \\alpha = (\\log \\mathcal{L}(\\rho') + \\log \\pi_0(\\rho')) - (\\log \\mathcal{L}(\\rho) - \\log \\pi_0(\\rho))\n",
    "$$\n",
    "\n",
    "4.  Generate a random number $r$ from a uniform distribution $U(0,1)$, calculate its logarithm, and compare it to $\\log \\alpha$. If $\\log r < \\log \\alpha$, accept the new state $\\rho'$, otherwise keep the current state $\\rho$.\n",
    "\n",
    "5. Repeat steps 2-4 for as many iterations as needed to build a Markov chain of density matrices.\n",
    "\n",
    "As part of the last steps, we get rid of the first 20% of the chain (burn-in) since they strongly depend on the initial guess $\\rho^{(0)}$, and average the remaining states to get the final estimate $\\hat\\rho_{BME}$. The log-likelihood is also averaged over the same chain.\n",
    "\n",
    "Without further ado, let's see how our BME reconstruction method performs on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "nrho = 5000\n",
    "num_bins = 400\n",
    "eps=0.01\n",
    "\n",
    "rho_est, logL_chain = run_BME(thetas-theta0, \n",
    "              x_values-x0,\n",
    "              num_bins=num_bins,\n",
    "              nrho=nrho,\n",
    "              N=N,\n",
    "              epsilon=eps\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid and parameters\n",
    "xvec = np.linspace(-4, 4, 200)\n",
    "X, Y = np.meshgrid(xvec, xvec)\n",
    "vmin, vmax = -1/np.pi, 1/np.pi\n",
    "levels = np.linspace(vmin, vmax, 41)\n",
    "\n",
    "# Precompute Wigner functions with QuTiP\n",
    "Ws = [wigner(Qobj(rho_est), xvec, xvec)]\n",
    "\n",
    "# Precompute the diagonal elements\n",
    "diagonals = [np.diag(rho_est).real]\n",
    "\n",
    "N = rho_est.shape[0]\n",
    "# Make array from 0 to N in steps of 1\n",
    "n_values = np.arange(0, N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9db12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1, 2, figsize=(14, 6),\n",
    "    gridspec_kw={'width_ratios': [1.5, 1]}\n",
    ")\n",
    "fig.subplots_adjust(wspace=0.15)\n",
    "\n",
    "# Subplot 1\n",
    "ax1.set_title('Wigner function')\n",
    "# Filled contours with transparency\n",
    "contour_filled = ax1.contourf(X, Y, Ws[-1], levels=levels,\n",
    "                            cmap='seismic', alpha=0.8, vmin=vmin, vmax=vmax)\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(contour_filled, ax=ax1, ticks=[-1/np.pi, 1/np.pi])\n",
    "cbar.ax.set_yticklabels([r\"$-1/\\pi$\", r\"$1/\\pi$\"])  # custom tick labels if needed\n",
    "# Move axes to cross at (0,0)\n",
    "ax1.spines['left'].set_position('zero')\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.spines['right'].set_color('none')\n",
    "ax1.spines['top'].set_color('none')\n",
    "# Set x- and y-ticks skipping 0\n",
    "ax1.set_xticks([-3, -2, -1, 1, 2, 3])\n",
    "ax1.set_yticks([-3, -2, -1, 1, 2, 3])\n",
    "PlotSettings(ax1, minimalist=True)\n",
    "\n",
    "# Subplot 2\n",
    "ax2.set_title('Photon statistics')\n",
    "\n",
    "for i in range(len(n_values)):\n",
    "    ax2.vlines(n_values[i], 0, diagonals[-1][i], colors='blue', linestyles='dashed')\n",
    "\n",
    "ax2.plot(n_values, diagonals[-1], 'o', color='blue')\n",
    "ax2.set_xlabel('Fock state |n>')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_xticks(n_values)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75927e7",
   "metadata": {},
   "source": [
    "### Benchmarks and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4785ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = [i for i in range(3, 11)]\n",
    "nbin_values = [i*20 for i in range(3, 11)]\n",
    "\n",
    "delta_ll_mle, runtime_grid_mle = run_iMLE_benchmark(\n",
    "    thetas, x_values, N_values, nbin_values,\n",
    "    tol=1e-2, max_iters=1000\n",
    ")\n",
    "\n",
    "delta_ll_bme, runtime_grid_bme = run_BME_benchmark(\n",
    "    thetas, x_values, N_values, nbin_values,[5000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a208697",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    delta_ll_mle, delta_ll_bme,\n",
    "    runtime_grid_mle, runtime_grid_bme,\n",
    "    N_values, nbin_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58119c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = [i for i in range(3, 11)]\n",
    "nbin_values = [i*20 for i in range(3, 11)]\n",
    "\n",
    "delta_ll_mle_2, runtime_grid_mle_2 = run_iMLE_benchmark(\n",
    "    thetas, x_values, N_values, nbin_values,\n",
    "    tol=1e-3, max_iters=1000\n",
    ")\n",
    "\n",
    "delta_ll_bme_2, runtime_grid_bme_2 = run_BME_benchmark(\n",
    "    thetas, x_values, N_values, nbin_values,[10000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05978ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    delta_ll_mle_2, delta_ll_bme_2,\n",
    "    runtime_grid_mle_2, runtime_grid_bme_2,\n",
    "    N_values, nbin_values\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
